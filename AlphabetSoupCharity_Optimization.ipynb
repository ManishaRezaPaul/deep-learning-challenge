{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFNWh-YDSj87"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 407,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "_iSgKLEOSj8_",
        "outputId": "76dd1719-a49a-4cd2-ba2c-55ecfe0a69bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf7b80f8-577d-498f-9d51-b97f9bf3ef6f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf7b80f8-577d-498f-9d51-b97f9bf3ef6f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf7b80f8-577d-498f-9d51-b97f9bf3ef6f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf7b80f8-577d-498f-9d51-b97f9bf3ef6f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6ab68fe7-5531-48d0-a1b1-74db9ea0f153\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ab68fe7-5531-48d0-a1b1-74db9ea0f153')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6ab68fe7-5531-48d0-a1b1-74db9ea0f153 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {
        "id": "YeGss9_9Sj9B"
      },
      "outputs": [],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(columns=[\"NAME\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19vwvAM5Sj9B",
        "outputId": "fb798653-7b7a-4cc7-c8c7-3cdaeaad9126"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EIN                       34299\n",
              "APPLICATION_TYPE             17\n",
              "AFFILIATION                   6\n",
              "CLASSIFICATION               71\n",
              "USE_CASE                      5\n",
              "ORGANIZATION                  4\n",
              "STATUS                        2\n",
              "INCOME_AMT                    9\n",
              "SPECIAL_CONSIDERATIONS        2\n",
              "ASK_AMT                    8747\n",
              "IS_SUCCESSFUL                 2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 409
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FekCKCEvSj9C",
        "outputId": "df7f8a13-4861-4149-e15d-b7e5b060539e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE\n",
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T14        3\n",
              "T25        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 411
        }
      ],
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_count = application_df.value_counts('APPLICATION_TYPE')\n",
        "\n",
        "application_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15XHjwwoSj9C",
        "outputId": "93607db7-6342-4cac-c502-98d6d6d6f548"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 412
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace = list(application_count[application_count<500].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 413,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWeVUbmXSj9D",
        "outputId": "bdfa1f99-3673-4d8b-c76a-c2619e45229a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C2190        1\n",
              "C2380        1\n",
              "C2500        1\n",
              "C2561        1\n",
              "C8210        1\n",
              "Length: 71, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 413
        }
      ],
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "classification_count = application_df.value_counts('CLASSIFICATION')\n",
        "classification_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxS7J_vPSj9D",
        "outputId": "03190073-4d45-4afb-ec0f-9c105e84ab9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C2300       32\n",
              "C7200       32\n",
              "C1240       30\n",
              "C8000       20\n",
              "C7120       18\n",
              "C1500       16\n",
              "C1800       15\n",
              "C6000       15\n",
              "C1250       14\n",
              "C8200       11\n",
              "C1278       10\n",
              "C1238       10\n",
              "C1235        9\n",
              "C1237        9\n",
              "C7210        7\n",
              "C1720        6\n",
              "C4100        6\n",
              "C2400        6\n",
              "C1600        5\n",
              "C1257        5\n",
              "C2710        3\n",
              "C1260        3\n",
              "C0           3\n",
              "C1267        2\n",
              "C1246        2\n",
              "C1256        2\n",
              "C3200        2\n",
              "C1234        2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ],
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "count_class = classification_count[classification_count > 1]\n",
        "count_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 415,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZwQKitGSj9D",
        "outputId": "d393dc53-36b0-4647-df4d-1b66c9cee2e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "Other     2261\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 415
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "classifications_to_replace =  classification_count[classification_count < 1000].index.tolist()\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 416,
      "metadata": {
        "id": "oQCLA5kISj9E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "0866b083-8726-4044-b269-aa515849ae9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN  STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0  10520599       1     5000              1                     0.0   \n",
              "1  10531628       1   108590              1                     0.0   \n",
              "2  10547893       1     5000              0                     0.0   \n",
              "3  10553066       1     6692              1                     0.0   \n",
              "4  10556103       1   142590              1                     0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                   1.0                   0.0                  0.0   \n",
              "1                   0.0                   0.0                  1.0   \n",
              "2                   0.0                   0.0                  0.0   \n",
              "3                   0.0                   0.0                  1.0   \n",
              "4                   0.0                   0.0                  1.0   \n",
              "\n",
              "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  ...  INCOME_AMT_1-9999  \\\n",
              "0                  0.0                  0.0  ...                0.0   \n",
              "1                  0.0                  0.0  ...                1.0   \n",
              "2                  0.0                  1.0  ...                0.0   \n",
              "3                  0.0                  0.0  ...                0.0   \n",
              "4                  0.0                  0.0  ...                0.0   \n",
              "\n",
              "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
              "0                     0.0                       0.0                 0.0   \n",
              "1                     0.0                       0.0                 0.0   \n",
              "2                     0.0                       0.0                 0.0   \n",
              "3                     1.0                       0.0                 0.0   \n",
              "4                     0.0                       1.0                 0.0   \n",
              "\n",
              "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
              "0               0.0                     0.0              0.0   \n",
              "1               0.0                     0.0              0.0   \n",
              "2               0.0                     0.0              0.0   \n",
              "3               0.0                     0.0              0.0   \n",
              "4               0.0                     0.0              0.0   \n",
              "\n",
              "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
              "0                0.0                       1.0                       0.0  \n",
              "1                0.0                       1.0                       0.0  \n",
              "2                0.0                       1.0                       0.0  \n",
              "3                0.0                       1.0                       0.0  \n",
              "4                0.0                       1.0                       0.0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d66c61f4-2486-40ed-8582-caa8340bb89d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d66c61f4-2486-40ed-8582-caa8340bb89d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d66c61f4-2486-40ed-8582-caa8340bb89d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d66c61f4-2486-40ed-8582-caa8340bb89d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78a9783c-ada8-44c3-9a34-b2445776e18a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78a9783c-ada8-44c3-9a34-b2445776e18a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78a9783c-ada8-44c3-9a34-b2445776e18a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 416
        }
      ],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_df = pd.get_dummies(application_df,dtype=float)\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "id": "2jTZPl4xSj9E"
      },
      "outputs": [],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = application_df['IS_SUCCESSFUL']\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X = application_df.drop(columns='IS_SUCCESSFUL')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "id": "yhm4I4rISj9F"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjMsXbCRSj9F"
      },
      "source": [
        "## Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 617,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBEZYDXCSj9F",
        "outputId": "fd24781f-a452-482d-9ddd-7a7aee8ba4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_134\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_407 (Dense)           (None, 100)               4500      \n",
            "                                                                 \n",
            " dense_408 (Dense)           (None, 90)                9090      \n",
            "                                                                 \n",
            " dense_409 (Dense)           (None, 1)                 91        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13681 (53.44 KB)\n",
            "Trainable params: 13681 (53.44 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len( X_train_scaled[0])\n",
        "hiddenlayer1=100\n",
        "hiddenlayer2=90\n",
        "hiddenlayer3=10\n",
        "# hiddenlayer4=1\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hiddenlayer1, activation=\"relu\", input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hiddenlayer2, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "# nn.add(tf.keras.layers.Dense(units=hiddenlayer3, activation=\"sigmoid\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 618,
      "metadata": {
        "id": "h_hy6C7-Sj9G"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 619,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVckForKSj9G",
        "outputId": "c06b26ce-a11c-4cf4-d402-fd5b6c0ded5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 1s 3ms/step - loss: 0.6062 - accuracy: 0.6838\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7301\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7321\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7330\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7322\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7345\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7352\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7360\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7365\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7380\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7369\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7360\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7369\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7372\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7386\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7400\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7390\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7388\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7401\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7403\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7381\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7405\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7411\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7418\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7421\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5322 - accuracy: 0.7423\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7395\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7409\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5315 - accuracy: 0.7417\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7435\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.7425\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7427\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7409\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7433\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7438\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7424\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7446\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7465\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7458\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7441\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7441\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7456\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7469\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7457\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7448\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7440\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7467\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7448\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7468\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7464\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7478\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7462\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7467\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7467\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7472\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7484\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7464\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7462\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7461\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7483\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7470\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7486\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7482\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7484\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7480\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7476\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7468\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7488\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7496\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7487\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7494\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7487\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7485\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7481\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7484\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7493\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7492\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7502\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7483\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7491\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7509\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7491\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5193 - accuracy: 0.7496\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5193 - accuracy: 0.7498\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7490\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5197 - accuracy: 0.7506\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5198 - accuracy: 0.7490\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7492\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5189 - accuracy: 0.7492\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7496\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7503\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7512\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7503\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7507\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7511\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7512\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7500\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7513\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7500\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7524\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7516\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7501\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7517\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7506\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7508\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7506\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7504\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7516\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7520\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7518\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7529\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7509\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7525\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7514\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7525\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7535\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7512\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7521\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7524\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7520\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7525\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7514\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7513\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7530\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7523\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7521\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7516\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7528\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7520\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7525\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7512\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7518\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7523\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7539\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7539\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7524\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7540\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5121 - accuracy: 0.7535\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7512\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.7524\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7539\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7540\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5122 - accuracy: 0.7523\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.7528\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7542\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7535\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5124 - accuracy: 0.7533\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7539\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7531\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7544\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7531\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7534\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7526\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7526\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7539\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7505\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7548\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7558\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7532\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7555\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7544\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7536\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7552\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7529\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7546\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7543\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7556\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7538\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7529\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7548\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7532\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7543\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7541\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7556\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7531\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7553\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7545\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7542\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7543\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7544\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7548\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7551\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7555\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7557\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7545\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7545\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7540\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7531\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5086 - accuracy: 0.7555\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7544\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7541\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7556\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7570\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7550\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7556\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7560\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7537\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5091 - accuracy: 0.7550\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7549\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7549\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.7557\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5088 - accuracy: 0.7543\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7551\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7556\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7560\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7552\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7545\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7563\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7548\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7554\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7565\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7566\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7555\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7548\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7572\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7572\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7556\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7567\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7542\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7563\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7565\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7569\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7551\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7566\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7564\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7553\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7570\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7544\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7559\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7552\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7557\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7559\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.7569\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7563\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7570\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7568\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7568\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7551\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7564\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7554\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7538\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7565\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7556\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7567\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7573\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7566\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7560\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7563\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7570\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7570\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7573\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5049 - accuracy: 0.7561\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7584\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.7553\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5051 - accuracy: 0.7580\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.7574\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5049 - accuracy: 0.7561\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7569\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.7567\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7589\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7566\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7574\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7561\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7563\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7573\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7572\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7562\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7574\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7573\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5045 - accuracy: 0.7568\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7564\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7582\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.7579\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7567\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7581\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7575\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7579\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7587\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.7576\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7570\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.7573\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7570\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7583\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7572\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7566\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7574\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.7573\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7574\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5045 - accuracy: 0.7580\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7580\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7561\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7577\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7571\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7575\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7575\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7574\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7580\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7577\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7589\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.7584\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5028 - accuracy: 0.7567\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 1s 11ms/step - loss: 0.5024 - accuracy: 0.7589\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5013 - accuracy: 0.7581\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5026 - accuracy: 0.7573\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.5023 - accuracy: 0.7580\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 1s 11ms/step - loss: 0.5036 - accuracy: 0.7578\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7598\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7569\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7589\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7580\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7574\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7579\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7584\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7591\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7577\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7582\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7582\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7565\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7580\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7593\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7577\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7593\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.7586\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7597\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.7583\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7607\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7588\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7571\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7586\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7600\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7589\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7593\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.7598\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7573\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7582\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7579\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7584\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7596\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7577\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7578\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7580\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7582\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7605\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7599\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7601\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7598\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7582\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7582\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5004 - accuracy: 0.7591\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5015 - accuracy: 0.7580\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7596\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7582\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.7582\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5011 - accuracy: 0.7575\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.7603\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.7580\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7561\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7575\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7583\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7585\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7587\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7569\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7596\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7586\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7592\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7593\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7593\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7595\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7595\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7587\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7576\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7600\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7582\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7601\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7590\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7593\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7600\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7587\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7601\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7596\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7605\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7596\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7601\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7594\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7587\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7592\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7585\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7589\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7599\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7595\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7584\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7577\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7586\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7592\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7630\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7584\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7599\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4982 - accuracy: 0.7596\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4982 - accuracy: 0.7587\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4985 - accuracy: 0.7598\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7593\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.7600\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4980 - accuracy: 0.7601\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7580\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7584\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7583\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7594\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7594\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7598\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7612\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7593\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7600\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.7596\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7595\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7601\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7590\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7596\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7594\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7589\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7605\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7599\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7593\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7615\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7606\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7604\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7593\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7598\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7585\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7612\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7593\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7594\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7614\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7607\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7602\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.7602\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7596\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4970 - accuracy: 0.7605\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7592\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7592\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7597\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7589\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7593\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7601\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7599\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.7585\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7611\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7606\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7610\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7605\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7598\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7594\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.7605\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7605\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7610\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7607\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7602\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4966 - accuracy: 0.7599\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7612\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.7610\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7606\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7598\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7608\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7588\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7605\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.7597\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7607\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7601\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7614\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.7604\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7608\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7614\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7609\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7603\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7605\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7602\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7608\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7611\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7598\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7609\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7592\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7607\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7618\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7618\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7605\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7625\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.7607\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7603\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7598\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7599\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7605\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7614\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7609\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.7609\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.7591\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7591\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7611\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7613\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7610\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7602\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.7600\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=500, batch_size = 500)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataframe to plot the loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "history_df = pd.DataFrame(fit_model.history)\n",
        "history_df.index += 1\n",
        "\n",
        "history_df.plot(y=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "3ifeiFobZ6TO",
        "outputId": "73d3c85d-066a-464f-d360-16a57d982b43"
      },
      "execution_count": 620,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 621,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmgGoKR9Sj9G",
        "outputId": "ab998a4b-a180-4e24-82fb-376734ff03ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5698 - accuracy: 0.7313 - 455ms/epoch - 2ms/step\n",
            "Loss: 0.5698291063308716, Accuracy: 0.7313119769096375\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "orQATsZ4Sj9G",
        "outputId": "74e58835-ba6e-4f30-f920-c091968518ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5ff09091-fa57-4a80-9e7a-617a95f498fa\", \"Model_1.h5\", 125264)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "from google.colab import files\n",
        "\n",
        "nn.save('/content/Model_1.h5')\n",
        "files.download('/content/Model_1.h5')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}